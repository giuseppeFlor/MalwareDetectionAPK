from androguard.misc import AnalyzeAPK
import os
from tqdm import tqdm
import ast
from sklearn.preprocessing import LabelEncoder
import pandas as pd
from ApiSequenceGenerator import *
import networkx as nx

no_listed_apks = []
with open('NO_LISTED_APKs.txt', 'r') as n:
  lines = n.readlines()
  for line in lines:
    if '\n' in line:
      line = line.replace('\n', '')
      no_listed_apks.append(line)

def assign_label(file, dict_object):
  label = dict_object[str(file)]
  print(label)
  return label

def get_api_call_graph(apk_file):
  # Carica il file APK in Androguard
  a, d, dx = AnalyzeAPK(apk_file)
  # Crea il grafo di chiamate API utilizzando Androguard
  api_call_graph = dx.get_call_graph("Lnet/maxicom|Lcom/software/|Ljava/security|Ljava/rmi|Ljava/io|Landroid/service/|Landroid/hardware|Landroid/util/|Landroid/os/|Landroid/content/|Landroid/media/|Landroid/net/|Landroid/app/|Landroid/nfc/|Landroid/location/|Landroid/accounts/|Landroid/bluetooth/|Landroid/provider/|Landroid/nfc/|Landroid/telecom|Landroid/telephony/|Ljava/net/|Ljavax/crypto/")
  print('The file is : ' + str(apk_file))
  nodes = api_call_graph.number_of_nodes()
  return api_call_graph, nodes

def apply_func(assign_label, get_api_call_graph, dict_object, number_of_nodes, path, folders, labels, api_call_graphs):
  for folder in folders:
    print('Analyzing folder : ' + folder)
    new_path = path + str(folder) + '\\' + str(folder)
    files = os.listdir(new_path)
    for file in tqdm(files):
      if file not in no_listed_apks:
        try:
          acg, number = get_api_call_graph(new_path + '\\' + file)
          d = nx.to_dict_of_dicts(acg)
          with open('GRAPHS\\' + str(file) + '.gml', 'w') as g:
            g.write(str(d))
          api_call_graphs.append(acg)
          number_of_nodes.append(number)
          label = assign_label(file, dict_object)
          labels.append(label)
        except Exception as e:
          print(e)
          pass

# Apri il file di testo in modalit√† lettura
def read_correspondences():
    with open("FINAL_DREBIN_CLASSIFIED", "r") as f:
    # Leggi il contenuto del file di testo in una stringa
      dict_string = f.read()
    return dict_string


def prepare():
    number_of_nodes = []
    path = ""
    folders = os.listdir(path)
    labels = []
    api_call_graphs = []
    return number_of_nodes,path,folders,labels,api_call_graphs

def preprocess(assign_label, get_api_call_graph, apply_func, read_correspondences, prepare):
    dict_string = read_correspondences()
    # Utilizza il modulo ast per valutare l'espressione Python nel file di testo
    dict_object = ast.literal_eval(dict_string)
    number_of_nodes, path, folders, labels, api_call_graphs = prepare()
    apply_func(assign_label, get_api_call_graph, dict_object, number_of_nodes, path, folders, labels, api_call_graphs)
    # Preprocessa i grafi di chiamate API
    preprocessor = ApiSequenceGenerator()
    api_call_sequences = preprocessor.preprocess(api_call_graphs)
    # Crea l'oggetto LabelEncoder
    encoder = LabelEncoder()
    # Codifica le etichette di testo come numeri interi
    labels = encoder.fit_transform(labels)
    return labels,api_call_sequences


# Crea il dataset come lista di tuple (sequenza, etichetta)
def create_dataset(labels, api_call_sequences):
    dataset = [(sequence, label) for sequence, label in zip(api_call_sequences, labels)]
    return dataset


def analyze_dataset(dataset):
    sequences = []
    labels = []

    # Scorri il dataset
    for data, label in dataset:
      sequences.append(data)
      labels.append(label)
    return sequences, labels

# converte ogni array in una stringa separata da virgole
def create_dataframe(sequences, labels):
    sequences_str = [' '.join(map(str, seq)) for seq in sequences]
    # crea il dataframe
    df = pd.DataFrame(sequences_str, columns=['sequences'])
    df['label'] = labels
    return df

def process_applications(assign_label, get_api_call_graph, apply_func, read_correspondences, prepare, preprocess, create_dataset, analyze_dataset, create_dataframe):
    labels, api_call_sequences = preprocess(assign_label, get_api_call_graph, apply_func, read_correspondences, prepare)
    print('[+] API Sequences have been created...\n')
    dataset = create_dataset(labels, api_call_sequences)
    print('[+] Dataset has been created...\n')
    sequences, labels = analyze_dataset(dataset)
    # Crea il CSV
    df = create_dataframe(sequences, labels)
    df.to_csv('TransformerDataset.csv')
    print('[+] CSV has been created !!!')


if __name__ == "__main__":
  process_applications(assign_label, get_api_call_graph, apply_func, read_correspondences, prepare, preprocess, create_dataset, analyze_dataset, create_dataframe)