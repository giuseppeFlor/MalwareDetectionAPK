{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"PY0eJ-DqydQH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698937787281,"user_tz":-60,"elapsed":22237,"user":{"displayName":"Giuseppe Floris","userId":"04737742060573701580"}},"outputId":"6900f7a7-906e-4921-9914-8cc93e8a64f8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"mgN0C4WS4Pz5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698937869158,"user_tz":-60,"elapsed":74702,"user":{"displayName":"Giuseppe Floris","userId":"04737742060573701580"}},"outputId":"a927b83a-e536-477f-ff87-60223620beab"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.8/511.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m115.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-datasets 4.9.3 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n","tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install -q -U \"tensorflow-text==2.9.*\"\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"jTeowLjCuyrA","executionInfo":{"status":"ok","timestamp":1698937873275,"user_tz":-60,"elapsed":4129,"user":{"displayName":"Giuseppe Floris","userId":"04737742060573701580"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import tensorflow_text\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import pandas as pd\n","import numpy as np\n","from sklearn.metrics import roc_curve, auc\n","from sklearn.metrics import precision_score, recall_score\n","from sklearn import metrics\n","from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_curve\n","from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n","import datetime\n","import os\n","import random\n","from sklearn.model_selection import train_test_split\n","from keras.utils import to_categorical\n","from scipy import interp"]},{"cell_type":"code","source":["bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n","bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/lambert_en_uncased_L-24_H-1024_A-16/2\")"],"metadata":{"id":"YIJch88QIaB1","executionInfo":{"status":"ok","timestamp":1698937979823,"user_tz":-60,"elapsed":106551,"user":{"displayName":"Giuseppe Floris","userId":"04737742060573701580"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":8,"metadata":{"id":"pisCIZlwRbm6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698938217891,"user_tz":-60,"elapsed":238071,"user":{"displayName":"Giuseppe Floris","userId":"04737742060573701580"}},"outputId":"410fed58-67c7-4d1f-fa8b-7cc627c0a011"},"outputs":[{"name":"stdout","output_type":"stream","text":["definisci le epoche: 100\n"]}],"source":["folder_name = \"Model_Classification\"\n","epoch = input(\"definisci le epoche: \")\n","\n","# ottieni la data corrente\n","today = datetime.date.today().strftime(\"%Y-%m-%d\")\n","\n","# creazione il nome completo della cartella\n","full_name = f\"{folder_name}_{epoch}_{today}\"\n","\n","# crea il percorso della cartella\n","folder_path = os.path.join(\"drive\", \"MyDrive\", full_name)\n","\n","# se la cartella esiste già, incrementa il numero di versione\n","version = 0\n","while os.path.exists(folder_path):\n","    version += 1\n","    full_name = f\"{folder_name}_{epoch}_{today}_v{version:02d}\"\n","    folder_path = os.path.join(\"drive\", \"MyDrive\", full_name)\n","\n","# crea la cartella\n","os.makedirs(folder_path)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"CF9nKnLwaB_d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698938219565,"user_tz":-60,"elapsed":1677,"user":{"displayName":"Giuseppe Floris","userId":"04737742060573701580"}},"outputId":"787447d8-d332-4957-8006-f3b35050a7e0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    1086\n","1     826\n","2     696\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":9}],"source":["# Caricamento del dataset Malware\n","df_malware = pd.read_csv('drive/MyDrive/Dataset_Malware.csv')\n","\n","# Pulizia Dataset\n","df_malware = df_malware.drop('Unnamed: 0', axis=1)\n","def replace_spaces(row):\n","  # Sostituzione di due spazi con \"zzz\", rimozione di tutti gli spazi e ripristino di \"zzz\" con uno spazio\n","  return str(row).replace(\"  \", \"zzz\").replace(' ', '').replace('zzz', ' ')\n","\n","df_malware[\"sequences\"] = df_malware[\"sequences\"].apply(replace_spaces)\n","df_malware = df_malware.reset_index()\n","df_malware = df_malware.drop('index', axis=1)\n","df_malware['sequences'] = df_malware['sequences'].str.lstrip()\n","\n","df_malware = df_malware[~df_malware['label'].isin([0, 9, 2, 5, 1, 7, 6])]\n","\n","# Raggruppamento del DataFrame in base alla colonna 'label'\n","grouped = df_malware.groupby(\"label\")\n","# Assegnazione del DataFrame originale a una nuova variabile\n","new_df = df_malware\n","\n","# Reimpostazione dell'indice del nuovo DataFrame e rimozione della colonna 'index' risultante\n","df_malware = new_df.reset_index()\n","df_malware = df_malware.drop('index', axis=1)\n","# Conversione della colonna \"sequences\" in stringhe\n","df_malware['sequences'] = df_malware['sequences'].astype(str)\n","\n","# Filtro su Sms torjan - spyware - Rootkit\n","class_mapping = {4:0, 8:1, 3:2}\n","\n","# Applicazione della mappatura definita al DataFrame per aggiornare i valori della colonna 'label\n","df_malware['label'] = df_malware['label'].map(class_mapping)\n","\n","# Calcolo del conteggio dei valori unici nella colonna 'label' dopo il mapping\n","df_malware['label'].value_counts()"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"ns2EV8osaO6d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698938223333,"user_tz":-60,"elapsed":3771,"user":{"displayName":"Giuseppe Floris","userId":"04737742060573701580"}},"outputId":"e223a1bc-0b3a-4bb2-aa65-c760bff01117"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    1586\n","2    1586\n","0    1586\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":10}],"source":["def generate_new_sequence(seq1, seq2):\n","    # Divisione della prima sequenza di API basata sugli spazi\n","    apis_seq1 = seq1.split()\n","    # Divisione della seconda sequenza di API basata sugli spazi\n","    apis_seq2 = seq2.split()\n","\n","    # Se una delle due sequenze ha meno di due API, restituire un messaggio di errore\n","    if len(apis_seq1) < 2 or len(apis_seq2) < 2:\n","        return \"Both sequences should have at least two APIs.\"\n","\n","    # Scelta di un numero casuale di API da prendere dalla prima sequenza (almeno 2)\n","    num_apis_seq1 = random.randint(2, len(apis_seq1))\n","\n","    # Selezione casuale di 'num_apis_seq1' API dalla prima sequenza\n","    cut_apis_seq1 = random.sample(apis_seq1, num_apis_seq1)\n","\n","    # Combinazione delle API selezionate dalla prima sequenza con la seconda sequenza\n","    new_sequence = cut_apis_seq1 + apis_seq2\n","    # Conversione della nuova sequenza combinata in una stringa, unendo gli elementi con spazi\n","    new_sequence_str = ' '.join(new_sequence)\n","\n","    # Restituzione della nuova sequenza come stringa\n","    return new_sequence_str\n","\n","# Trova il numero di sequenze con label 0\n","num_samples_label_0 = df_malware[df_malware['label'] == 0].shape[0]\n","\n","# Trova il numero di sequenze con label 1\n","num_samples_label_1 = df_malware[df_malware['label'] == 1].shape[0]\n","\n","# Trova il numero di sequenze con label 2\n","num_samples_label_2 = df_malware[df_malware['label'] == 2].shape[0]\n","\n","# Calcola il numero di sequenze da aggiungere per raggiungere lo stesso numero di sequenze con label 2\n","num_samples_to_add_0 = 500\n","num_samples_to_add_1 = 500+  num_samples_label_0 - num_samples_label_1\n","num_samples_to_add_2 = 500+ num_samples_label_0 - num_samples_label_2\n","\n","# Crea un dataframe vuoto per le nuove sequenze\n","new_sequences_0 = pd.DataFrame(columns=['sequences', 'label'])\n","new_sequences_1 = pd.DataFrame(columns=['sequences', 'label'])\n","new_sequences_2 = pd.DataFrame(columns=['sequences', 'label'])\n","# Itera per il numero di sequenze da aggiungere per la classe 0\n","for i in range(num_samples_to_add_0):\n","    random_sequence = df_malware[df_malware['label'] == 0].sample(2)\n","    modified_sequence = generate_new_sequence(random_sequence.iloc[0]['sequences'], random_sequence.iloc[1]['sequences'])\n","    modified_sequence = modified_sequence.replace(\"<init>\", \"\")\n","    # Aggiungi la nuova sequenza al dataframe con la label 0\n","    new_row = pd.DataFrame({'sequences': [modified_sequence], 'label': [0]})\n","    new_sequences_0= pd.concat([new_sequences_0, new_row], ignore_index=True)\n","\n","\n","# Itera per il numero di sequenze da aggiungere per la classe 0\n","for i in range(num_samples_to_add_1):\n","    random_sequence = df_malware[df_malware['label'] == 1].sample(2)\n","    modified_sequence = generate_new_sequence(random_sequence.iloc[0]['sequences'], random_sequence.iloc[1]['sequences'])\n","    modified_sequence = modified_sequence.replace(\"<init>\", \"\")\n","    # Aggiungi la nuova sequenza al dataframe con la label 0\n","    new_row = pd.DataFrame({'sequences': [modified_sequence], 'label': [1]})\n","    new_sequences_1 = pd.concat([new_sequences_1, new_row], ignore_index=True)\n","\n","# Itera per il numero di sequenze da aggiungere per la classe 2\n","for i in range(num_samples_to_add_2):\n","    random_sequence = df_malware[df_malware['label'] == 2].sample(2)\n","    modified_sequence = generate_new_sequence(random_sequence.iloc[0]['sequences'], random_sequence.iloc[1]['sequences'])\n","    modified_sequence = modified_sequence.replace(\"<init>\", \"\")\n","    # Aggiungi la nuova sequenza al dataframe con la label 0\n","    new_row = pd.DataFrame({'sequences': [modified_sequence], 'label': [2]})\n","    new_sequences_2 = pd.concat([new_sequences_2, new_row], ignore_index=True)\n","\n","# Concatena il dataframe originale con le nuove sequenze\n","df_balanced = pd.concat([df_malware, new_sequences_0, new_sequences_1, new_sequences_2], ignore_index=True)\n","\n","df_malware.to_csv(os.path.join(folder_path, 'df_balanced_new.csv'), index=False)\n","\n","# Il dataframe ora contiene un numero uguale di sequenze per ogni classe\n","df_balanced['label'].value_counts()\n","\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"UTLPv2ErU6r2","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"error","timestamp":1698938248704,"user_tz":-60,"elapsed":25373,"user":{"displayName":"Giuseppe Floris","userId":"04737742060573701580"}},"outputId":"bb68afc0-e0b1-4180-a811-426e9be3897c"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.0    892\n","1.0    892\n","2.0    892\n","Name: label, dtype: int64\n","2.0    397\n","0.0    397\n","1.0    396\n","Name: label, dtype: int64\n","1.0    298\n","0.0    297\n","2.0    297\n","Name: label, dtype: int64\n","Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," text (InputLayer)              [(None,)]            0           []                               \n","                                                                                                  \n"," keras_layer (KerasLayer)       {'input_word_ids':   0           ['text[0][0]']                   \n","                                (None, 128),                                                      \n","                                 'input_mask': (Non                                               \n","                                e, 128),                                                          \n","                                 'input_type_ids':                                                \n","                                (None, 128)}                                                      \n","                                                                                                  \n"," keras_layer_1 (KerasLayer)     {'default': (None,   335141889   ['keras_layer[0][0]',            \n","                                1024),                            'keras_layer[0][1]',            \n","                                 'sequence_output':               'keras_layer[0][2]']            \n","                                 (None, 128, 1024),                                               \n","                                 'pooled_output': (                                               \n","                                None, 1024),                                                      \n","                                 'encoder_outputs':                                               \n","                                 [(None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                ]}                                                                \n","                                                                                                  \n"," dropout (Dropout)              (None, 1024)         0           ['keras_layer_1[0][25]']         \n","                                                                                                  \n"," inter_layer (Dense)            (None, 1024)         1049600     ['dropout[0][0]']                \n","                                                                                                  \n"," intermediate_layer (Dense)     (None, 2048)         2099200     ['inter_layer[0][0]']            \n","                                                                                                  \n"," ultimate_layer (Dense)         (None, 4096)         8392704     ['intermediate_layer[0][0]']     \n","                                                                                                  \n"," last_layer (Dense)             (None, 4096)         16781312    ['ultimate_layer[0][0]']         \n","                                                                                                  \n"," output (Dense)                 (None, 3)            12291       ['last_layer[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 363,476,996\n","Trainable params: 28,335,107\n","Non-trainable params: 335,141,889\n","__________________________________________________________________________________________________\n","None\n","Epoch 1/100\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-4377e9c3ca38>\u001b[0m in \u001b[0;36m<cell line: 71>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m# Avvio training del modello\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=int(epoch), verbose=1,\n\u001b[0m\u001b[1;32m     72\u001b[0m           callbacks=[checkpoint, earlystopping, csv_logger])\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m       _, _, filtered_flat_args = (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["df_Train = df_balanced\n","\n","# pulizia e adeguamenti dataset per TensorFlow\n","df_Train['sequences'] = df_Train['sequences'].str.lstrip()\n","df_Train['sequences'] = df_Train['sequences'].astype(str)\n","df_Train['label'] = df_Train['label'].astype(np.float32)\n","\n","# Salvataggio del DataFrame pronto per il training come file CSV\n","df_Train.to_csv(os.path.join(folder_path, 'Dataset_bilanciato_training_classification.csv'), index=False)\n","\n","# Divisione dei dati in set di allenamento e test, con stratificazione per la colonna 'label'\n","X_train, X_test, y_train, y_test = train_test_split(df_Train['sequences'], df_Train['label'], stratify=df_Train['label'])\n","# Ulteriore divisione del set di allenamento in set di allenamento e di validazione, anch'essa stratificata\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, stratify=y_train)\n","\n","# Visualizzazione delle distribuzioni delle etichette nei set di allenamento, test e validazione\n","print(y_train.value_counts())\n","print(y_test.value_counts())\n","print(y_val.value_counts())\n","\n","# Conversione delle etichette in una forma one-hot encoding per l'allenamento del modello\n","y_train = to_categorical(y_train, num_classes=3)\n","y_test = to_categorical(y_test, num_classes=3)\n","y_val = to_categorical(y_val, num_classes=3)\n","\n","# Definizione dei layer per l'architettura BERT\n","text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n","preprocessed_text = bert_preprocess(text_input)\n","outputs = bert_encoder(preprocessed_text)\n","\n","# Definizione di layer aggiuntivi per la rete neurale\n","l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n","l = tf.keras.layers.Dense(1024, activation='relu', name='inter_layer')(l)\n","l = tf.keras.layers.Dense(2048, activation='relu', name='intermediate_layer')(l)\n","l = tf.keras.layers.Dense(4096, activation='relu', name='ultimate_layer')(l)\n","l = tf.keras.layers.Dense(4096, activation='relu', name='last_layer')(l)\n","\n","# Layer finale con funzione di attivazione softmax per la classificazione\n","l = tf.keras.layers.Dense(3, activation='softmax', name=\"output\")(l)\n","\n","# Costruzione del modello finale utilizzando gli input e output definiti\n","model = tf.keras.Model(inputs=[text_input], outputs=[l])\n","# Stampa del riassunto del modello\n","print(model.summary())\n","\n","# Definizione delle metriche di valutazione del modello\n","METRICS = [\n","    tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n","    tf.keras.metrics.Precision(name='precision'),\n","    tf.keras.metrics.Recall(name='recall')\n","]\n","\n","# Callback per interrompere l'allenamento quando una metrica smette di migliorare\n","earlystopping = EarlyStopping(monitor='val_loss', mode='min', patience=5, verbose=1)\n","# Callback per salvare il modello migliore basandosi sul valore minimo della perdita di validazione\n","checkpoint = ModelCheckpoint(os.path.join(folder_path, 'modello_Classidication.h5'),\n","                             monitor='val_loss', mode='min', verbose=1,\n","                             save_best_only=True, save_freq='epoch')\n","\n","# Compilazione del modello con l'ottimizzatore, la funzione di perdita e le metriche specificate\n","model.compile(optimizer='adam',\n","              loss=tf.keras.losses.CategoricalCrossentropy(),\n","              metrics=METRICS)\n","\n","# Definizione del percorso del file di log per registrare il progresso dell'allenamento\n","log_path = os.path.join(folder_path, \"training_log_Calssification.csv\")\n","# Callback per registrare i dati di allenamento su disco\n","csv_logger = tf.keras.callbacks.CSVLogger(log_path, separator=',', append=False)\n","\n","# Avvio training del modello\n","model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=int(epoch), verbose=1,\n","          callbacks=[checkpoint, earlystopping, csv_logger])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nBj1o1NcZDoP"},"outputs":[],"source":["# pulizia e adeguamenti dataset di test per TensorFlow\n","df_malware['sequences'] = df_malware['sequences'].str.lstrip()\n","df_malware['sequences'] = df_malware['sequences'].astype(str)\n","df_malware['label'] = df_malware['label'].astype(np.float32)\n","\n","# Suddivisione del dataset in sottoinsiemi per l'addestramento e il test.\n","X_train_test, X_test_unb, y_train_test, y_test_unb = train_test_split(df_malware['sequences'], df_malware['label'], stratify=df_malware['label'])\n","\n","y_test_unb = to_categorical(y_test_unb, num_classes=3)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pEIajYaGtJXs"},"outputs":[],"source":["# Valutazione del modello sul set di test non bilanciato\n","result = model.evaluate(X_test_unb, y_test_unb, verbose=1)\n","# Stampa del valore della perdita sul set di test\n","print(f\"Loss value: {result[0]}\")\n","# Stampa dell'accuratezza del modello sul set di test\n","print(f\"Accuracy: {result[1]}\")\n","# Stampa della precisione del modello sul set di test\n","print(f\"Precision: {result[2]}\")\n","# Stampa del recall del modello sul set di test\n","print(f\"Recall: {result[3]}\")\n","\n","# Predizioni del modello sul set di test\n","y_pred = model.predict(X_test_unb)\n","# Estrazione dell'indice della classe con la probabilità più alta per ciascuna predizione\n","y_pred = tf.argmax(y_pred, axis=1)\n","# Estrazione delle etichette vere dal set di test\n","y_true = y_test_unb\n","# Conversione delle etichette vere da one-hot encoding a indici\n","y_true = np.argmax(y_true, axis=1)\n","# Conversione delle etichette vere in un tensore TensorFlow\n","y_true = tf.convert_to_tensor(y_true, dtype=tf.float32)\n","\n","# Generazione e stampa di un report di classificazione, fornendo precisione, recall, f1-score per classe\n","report = metrics.classification_report(y_true, y_pred, digits=3)\n","print(\"Classification report: \")\n","print(report)\n","\n","# Salvataggio del report di classificazione su un file di testo\n","summary_path = os.path.join(folder_path, 'classification_report.txt')\n","with open(summary_path, 'w') as f:\n","    f.write(report)\n","\n","# Creazione di un grafico a matrice di confusione per visualizzare le prestazioni del modello\n","fig, ax = plt.subplots(figsize=(5, 5))\n","metrics.ConfusionMatrixDisplay.from_predictions(y_true, y_pred).plot(ax=ax)\n","# Salvataggio della matrice di confusione come immagine PNG\n","plt.savefig(os.path.join(folder_path, \"confusionMatrix.png\"))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d3Xp6ULVtTFv"},"outputs":[],"source":["\n","y_pred_unb = model.predict(X_test_unb)\n","# Calcola il punteggio ROC-AUC per ogni classe\n","fpr = dict()\n","tpr = dict()\n","roc_auc = dict()\n","n_classes = 3\n","\n","for i in range(n_classes):\n","    fpr[i], tpr[i], _ = roc_curve(y_test_unb[:, i], y_pred_unb[:, i])\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","# Calcola la curva ROC micro-media\n","fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_unb.ravel(), y_pred_unb.ravel())\n","roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n","\n","# Calcola la curva ROC macro-media e l'AUC\n","all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n","mean_tpr = np.zeros_like(all_fpr)\n","for i in range(n_classes):\n","    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n","mean_tpr /= n_classes\n","fpr[\"macro\"] = all_fpr\n","tpr[\"macro\"] = mean_tpr\n","roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n","\n","labels = [0, 1, 2]\n","class_names = ['Spyware', 'Rootkit', 'SMS-Trojan']\n","fig, ax = plt.subplots(figsize=(25, 25))\n","# plotta la curva ROC per ogni classe\n","for i in range(len(labels)):\n","  try:\n","    plt.plot(fpr[i], tpr[i], label='{} (AUC = {:.4f})'.format(class_names[i], round(roc_auc[i], 3)))\n","  except Exception as e:\n","    print(\"ex \", str(e))\n","# imposta le etichette degli assi e la legenda\n","plt.xlabel('False Positive Rate',fontsize=fig.get_figwidth()*2)\n","plt.ylabel('True Positive Rate',fontsize=fig.get_figwidth()*2)\n","plt.title('ROC Curve',fontsize=fig.get_figwidth()*2)\n","plt.legend(loc=\"lower right\", fontsize='large')\n","plt.savefig(os.path.join(folder_path, \"roc_curve.png\"))\n","# imposta la dimensione della figura in pollici\n","fig.set_size_inches(10, 10)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1YsLMIPFYfhe9hmi1iZa2EvN6x8p0L2FC","timestamp":1697980834513}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}