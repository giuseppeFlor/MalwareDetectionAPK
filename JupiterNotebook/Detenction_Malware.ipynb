{"cells":[{"cell_type":"code","execution_count":20,"metadata":{"id":"PY0eJ-DqydQH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698937658781,"user_tz":-60,"elapsed":5954,"user":{"displayName":"Giuseppe Floris","userId":"04737742060573701580"}},"outputId":"52461621-9763-4e9a-e1bb-db468666d166"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mgN0C4WS4Pz5"},"outputs":[],"source":["!pip install -q -U \"tensorflow-text==2.9.*\"\n"]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import tensorflow_text\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import pandas as pd\n","import numpy as np\n","from sklearn.metrics import roc_curve, auc\n","from sklearn.metrics import precision_score, recall_score\n","from sklearn import metrics\n","from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_curve, f1_score,accuracy_score\n","from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n","import datetime\n","import os\n","import random\n","from sklearn.model_selection import train_test_split\n","from keras.utils import to_categorical\n","from scipy import interp"],"metadata":{"id":"9AkzkO4-cIw2","executionInfo":{"status":"ok","timestamp":1698937665811,"user_tz":-60,"elapsed":278,"user":{"displayName":"Giuseppe Floris","userId":"04737742060573701580"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n","bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/lambert_en_uncased_L-24_H-1024_A-16/2\")"],"metadata":{"id":"o8I2iaTVKcqz"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":22,"metadata":{"id":"pisCIZlwRbm6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698937672814,"user_tz":-60,"elapsed":3332,"user":{"displayName":"Giuseppe Floris","userId":"04737742060573701580"}},"outputId":"b4d26e30-feb0-42af-8404-e41964c3fd72"},"outputs":[{"name":"stdout","output_type":"stream","text":["definisci le epoche: 100\n"]}],"source":["\n","# definisci la parte fissa del nome della cartella\n","folder_name = \"Model_Binary_Classification\"\n","\n","epoch = input(\"definisci le epoche: \")\n","\n","# ottieni la data corrente\n","today = datetime.date.today().strftime(\"%Y-%m-%d\")\n","\n","# creazione il nome completo della cartella\n","full_name = f\"{folder_name}_{epoch}_{today}\"\n","\n","# crea il percorso della cartella\n","folder_path = os.path.join(\"drive\", \"MyDrive\", full_name)\n","\n","# se la cartella esiste gi√†, incrementa il numero di versione\n","version = 0\n","while os.path.exists(folder_path):\n","    version += 1\n","    full_name = f\"{folder_name}_{epoch}_{today}_v{version:02d}\"\n","    folder_path = os.path.join(\"drive\", \"MyDrive\", full_name)\n","\n","# crea la cartella\n","os.makedirs(folder_path)"]},{"cell_type":"code","source":["\n","df = pd.read_csv('drive/MyDrive/Dataset_Benign.csv')\n","df_malware = pd.read_csv('drive/MyDrive/Dataset_Malware.csv')\n","\n","# Pulizia Dataset Benignin\n","df = df.drop('Unnamed: 0', axis=1)\n","def replace_spaces(row):\n","  return str(row).replace(\"  \", \"zzz\").replace(' ', '').replace('zzz', ' ')\n","\n","df[\"sequences\"] = df[\"sequences\"].apply(replace_spaces)\n","df = df.reset_index()\n","df = df.drop('index', axis=1)\n","df['sequences'] = df['sequences'].str.lstrip()\n","\n","df_benign = df\n","\n","\n","# Pulizia Dataset Malware\n","df_malware = df_malware.drop('Unnamed: 0', axis=1)\n","\n","def replace_spaces(row):\n","  return str(row).replace(\"  \", \"zzz\").replace(' ', '').replace('zzz', ' ')\n","\n","df_malware[\"sequences\"] = df_malware[\"sequences\"].apply(replace_spaces)\n","df_malware = df_malware.reset_index()\n","df_malware = df_malware.drop('index', axis=1)\n","df_malware['sequences'] = df_malware['sequences'].str.lstrip()\n","df_malware = df_malware[~df_malware['label'].isin([0, 9, 2, 5, 1, 7, 6])]\n","\n","\n","# Raggruppa i tweet in base alla label\n","grouped = df_malware.groupby(\"label\")\n","new_df = df_malware\n","\n","# Filtro su Sms torjan - spyware - Rootkit\n","class_mapping = {4: 0, 8: 1, 3: 2}\n","# Sostituisci le vecchie classi con le nuove classi\n","\n","new_df['label'] = new_df['label'].map(class_mapping)\n","df =new_df\n","\n","print(\"classi malware\" ,df['label'].value_counts())\n","print(\"classi Benign\" ,df_benign['label'].value_counts())"],"metadata":{"id":"CF9nKnLwaB_d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698937680669,"user_tz":-60,"elapsed":5896,"user":{"displayName":"Giuseppe Floris","userId":"04737742060573701580"}},"outputId":"656e8ae3-5198-40e8-80c4-f025292d0de8"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["classi malware 0    1086\n","1     826\n","2     696\n","Name: label, dtype: int64\n","classi Benign 0    4036\n","Name: label, dtype: int64\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import random\n","\n","def generate_new_sequence(seq1, seq2):\n","    apis_seq1 = seq1.split()\n","    apis_seq2 = seq2.split()\n","\n","    if len(apis_seq1) < 2 or len(apis_seq2) < 2:\n","        return \"Both sequences should have at least two APIs.\"\n","\n","    num_apis_seq1 = random.randint(2, len(apis_seq1))\n","\n","    cut_apis_seq1 = random.sample(apis_seq1, num_apis_seq1)\n","\n","\n","    new_sequence = cut_apis_seq1 + apis_seq2\n","    new_sequence_str = ' '.join(new_sequence)\n","\n","    return new_sequence_str\n","# Trova il numero di sequenze con label 0\n","num_samples_label_0 = df[df['label'] == 0].shape[0]\n","\n","# Trova il numero di sequenze con label 1\n","num_samples_label_1 = df[df['label'] == 1].shape[0]\n","\n","# Trova il numero di sequenze con label 2\n","num_samples_label_2 = df[df['label'] == 2].shape[0]\n","\n","# Calcola il numero di sequenze da aggiungere per raggiungere lo stesso numero di sequenze con label 2\n","num_samples_to_add_1 = num_samples_label_0 - num_samples_label_1\n","num_samples_to_add_2 = num_samples_label_0 - num_samples_label_2\n","\n","# Crea un dataframe vuoto per le nuove sequenze\n","new_sequences_1 = pd.DataFrame(columns=['sequences', 'label'])\n","new_sequences_2 = pd.DataFrame(columns=['sequences', 'label'])\n","# Itera per il numero di sequenze da aggiungere per la classe 0\n","\n","\n","\n","# Itera per il numero di sequenze da aggiungere per la classe 0\n","for i in range(num_samples_to_add_1):\n","    random_sequence = df[df['label'] == 1].sample(2)\n","    modified_sequence = generate_new_sequence(random_sequence.iloc[0]['sequences'], random_sequence.iloc[1]['sequences'])\n","    modified_sequence = modified_sequence.replace(\"<init>\", \"\")\n","    # Aggiungi la nuova sequenza al dataframe con la label 0\n","    new_row = pd.DataFrame({'sequences': [modified_sequence], 'label': [1]})\n","    new_sequences_1 = pd.concat([new_sequences_1, new_row], ignore_index=True)\n","\n","# Itera per il numero di sequenze da aggiungere per la classe 2\n","for i in range(num_samples_to_add_2):\n","    random_sequence = df[df['label'] == 2].sample(2)\n","    modified_sequence = generate_new_sequence(random_sequence.iloc[0]['sequences'], random_sequence.iloc[1]['sequences'])\n","    modified_sequence = modified_sequence.replace(\"<init>\", \"\")\n","    # Aggiungi la nuova sequenza al dataframe con la label 0\n","    new_row = pd.DataFrame({'sequences': [modified_sequence], 'label': [2]})\n","    new_sequences_2 = pd.concat([new_sequences_2, new_row], ignore_index=True)\n","\n","# Concatena il dataframe originale con le nuove sequenze\n","df_balanced = pd.concat([df, new_sequences_1, new_sequences_2], ignore_index=True)\n","\n","df_malware.to_csv(os.path.join(folder_path, 'df_balanced_new.csv'), index=False)\n","# Il dataframe ora contiene un numero uguale di sequenze per ogni classe\n","df_balanced['label'].value_counts()"],"metadata":{"id":"ns2EV8osaO6d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698937686031,"user_tz":-60,"elapsed":1461,"user":{"displayName":"Giuseppe Floris","userId":"04737742060573701580"}},"outputId":"39f63a67-c34b-4af2-ca37-a5bceda6557d"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    1086\n","2    1086\n","0    1086\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["\n","df_benign = df_benign.head(3258)\n","# Crea un dizionario per mappare le vecchie classi alle nuove classi\n","class_mapping = {0: 1, 1:1, 2: 1}\n","# Etichetto tutti i malware con classe 1\n","df_balanced['label'] = df_balanced['label'].map(class_mapping)\n","# unisco i due dataset Benign (classe 0) malware (classe 1)\n","df_Train = pd.concat([df_benign,df_balanced], axis=0)\n","df_Train = df_Train.reset_index()\n","df_Train = df_Train.drop('index', axis=1)\n","print(\"classi\" ,df_Train['label'].value_counts())"],"metadata":{"id":"k497koCphLBu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698937688899,"user_tz":-60,"elapsed":358,"user":{"displayName":"Giuseppe Floris","userId":"04737742060573701580"}},"outputId":"ddf89de7-321e-48c8-b865-eb40636f1c40"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["classi 0    3258\n","1    3258\n","Name: label, dtype: int64\n"]}]},{"cell_type":"code","source":["# pulizia e adeguamenti dataset per TensorFlow\n","df_Train['sequences'] = df_Train['sequences'].str.lstrip()\n","df_Train['sequences'] = df_Train['sequences'].astype(str)\n","df_Train['label'] = df_Train['label'].astype(np.float32)\n","\n","# Salvataggio del DataFrame pronto per il training come file CSV\n","df_Train.to_csv(os.path.join(folder_path, 'Dataset_bilanciato_training_detection.csv'), index=False)\n","\n","# Divisione dei dati in set di allenamento e test, con stratificazione per la colonna 'label'\n","X_train, X_test, y_train, y_test = train_test_split(df_Train['sequences'],df_Train['label'], stratify=df_Train['label'])\n","# Ulteriore divisione del set di allenamento in set di allenamento e di validazione, anch'essa stratificata\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, stratify=y_train)\n","# Visualizzazione delle distribuzioni delle etichette nei set di allenamento, test e validazione\n","print(y_train.value_counts())\n","print(y_test.value_counts())\n","print(y_val.value_counts())\n","\n","# Definizione dei layer per l'architettura BERT\n","text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n","preprocessed_text = bert_preprocess(text_input)\n","outputs = bert_encoder(preprocessed_text)\n","\n","# Definizione di layer aggiuntivi per la rete neurale\n","l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n","l = tf.keras.layers.Dense(1024, activation='relu',  name='inter_layer')(l)\n","l = tf.keras.layers.Dense(2048, activation='relu',  name='intermediate_layer')(l)\n","l = tf.keras.layers.Dense(4096, activation='relu',  name='ultimate_layer')(l)\n","\n","# Layer finale con funzione di attivazione softmax per la classificazione\n","l = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(l)\n","\n","# Costruzione del modello finale utilizzando gli input e output definiti\n","model = tf.keras.Model(inputs=[text_input], outputs = [l])\n","\n","# Stampa del riassunto del modello\n","print(model.summary())\n","\n","# Definizione delle metriche di valutazione del modello\n","METRICS = [\n","      tf.keras.metrics.BinaryAccuracy('accuracy'),\n","      tf.keras.metrics.Precision(name='precision'),\n","      tf.keras.metrics.Recall(name='recall')\n","]\n","\n","# Callback per interrompere l'allenamento quando una metrica smette di migliorare\n","earlystopping = EarlyStopping(monitor='val_loss', mode='min', patience=5, verbose=1)\n","# Callback per salvare il modello migliore basandosi sul valore minimo della perdita di validazione\n","checkpoint = ModelCheckpoint(os.path.join(folder_path, 'modello.h5'),   # I save in the older Keras H5 format due to a Tensorflow 2.7 bug\n","        monitor='val_loss', mode='min', verbose=1,\n","        save_best_only=True, save_freq='epoch'\n",")\n","\n","# Compilazione del modello con l'ottimizzatore, la funzione di perdita e le metriche specificate\n","model.compile(optimizer='adam',\n","              loss=tf.keras.losses.BinaryCrossentropy(),\n","              metrics=METRICS)\n","\n","# Definizione del percorso del file di log per registrare il progresso dell'allenamento\n","log_path = os.path.join(folder_path, \"training_log_detection.csv\")\n","\n","# Callback per registrare i dati di allenamento su disco\n","csv_logger = tf.keras.callbacks.CSVLogger(log_path, separator=',', append=False)\n","# Avvio training del modello\n","model.fit(X_train, y_train, validation_data=[X_val, y_val], epochs=int(epoch), verbose=1,\n","    callbacks=[checkpoint,earlystopping,csv_logger])"],"metadata":{"id":"UTLPv2ErU6r2","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1698937869683,"user_tz":-60,"elapsed":177997,"user":{"displayName":"Giuseppe Floris","userId":"04737742060573701580"}},"outputId":"a774a967-2473-4a3d-828e-5346105b5f6d"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["0.0    1833\n","1.0    1832\n","Name: label, dtype: int64\n","1.0    815\n","0.0    814\n","Name: label, dtype: int64\n","1.0    611\n","0.0    611\n","Name: label, dtype: int64\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," text (InputLayer)              [(None,)]            0           []                               \n","                                                                                                  \n"," keras_layer (KerasLayer)       {'input_word_ids':   0           ['text[0][0]']                   \n","                                (None, 128),                                                      \n","                                 'input_mask': (Non                                               \n","                                e, 128),                                                          \n","                                 'input_type_ids':                                                \n","                                (None, 128)}                                                      \n","                                                                                                  \n"," keras_layer_1 (KerasLayer)     {'sequence_output':  335141889   ['keras_layer[1][0]',            \n","                                 (None, 128, 1024),               'keras_layer[1][1]',            \n","                                 'encoder_outputs':               'keras_layer[1][2]']            \n","                                 [(None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                , (None, 128, 1024)                                               \n","                                ],                                                                \n","                                 'default': (None,                                                \n","                                1024),                                                            \n","                                 'pooled_output': (                                               \n","                                None, 1024)}                                                      \n","                                                                                                  \n"," dropout (Dropout)              (None, 1024)         0           ['keras_layer_1[1][25]']         \n","                                                                                                  \n"," inter_layer (Dense)            (None, 1024)         1049600     ['dropout[0][0]']                \n","                                                                                                  \n"," intermediate_layer (Dense)     (None, 2048)         2099200     ['inter_layer[0][0]']            \n","                                                                                                  \n"," ultimate_layer (Dense)         (None, 4096)         8392704     ['intermediate_layer[0][0]']     \n","                                                                                                  \n"," output (Dense)                 (None, 1)            4097        ['ultimate_layer[0][0]']         \n","                                                                                                  \n","==================================================================================================\n","Total params: 346,687,490\n","Trainable params: 11,545,601\n","Non-trainable params: 335,141,889\n","__________________________________________________________________________________________________\n","None\n","Epoch 1/100\n","111/115 [===========================>..] - ETA: 6s - loss: 0.3452 - accuracy: 0.8660 - precision: 0.8545 - recall: 0.8824"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-248aab7fab87>\u001b[0m in \u001b[0;36m<cell line: 64>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mcsv_logger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCSVLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m# Avvio training del modello\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m model.fit(X_train, y_train, validation_data=[X_val, y_val], epochs=int(epoch), verbose=1,\n\u001b[0m\u001b[1;32m     65\u001b[0m     callbacks=[checkpoint,earlystopping,csv_logger])\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# pulizia e adeguamenti dataset di test per TensorFlow\n","df_Test = pd.concat([df_benign,df], axis=0)\n","df_Test = df_Train.reset_index()\n","df_Test = df_Test.drop('index', axis=1)\n","df_Test['sequences'] = df_Test['sequences'].str.lstrip()\n","df_Test['sequences'] = df_Test['sequences'].astype(str)\n","df_Test['label'] = df_Test['label'].astype(np.float32)\n","\n","# Suddivisione del dataset in sottoinsiemi per l'addestramento e il test.\n","X_train_test, X_test_unb, y_train_test, y_test_unb = train_test_split(df_Test['sequences'],df_Test['label'], stratify=df_Test['label'])\n"],"metadata":{"id":"lVYSaCSCIltw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Valutazione del modello sul set di test non bilanciato\n","result = model.evaluate(X_test_unb, y_test_unb, verbose=1)\n","# Stampa del valore della perdita sul set di test\n","print(f\"Loss value: {result[0]}\")\n","# Stampa dell'accuratezza del modello sul set di test\n","print(f\"Accuracy: {result[1]}\")\n","# Stampa della precisione del modello sul set di test\n","print(f\"Precision: {result[2]}\")\n","# Stampa del recall del modello sul set di test\n","print(f\"Recall: {result[3]}\")\n","# Convert probability scores to binary labels\n","\n","\n","X_train = X_train.astype(str)\n","len(X_train), len(y_train)\n","bert_preds = model.predict(X_test_unb)\n","bert_f1 = f1_score(y_test_unb, bert_preds.round())\n","bert_roc_auc = roc_auc_score(y_test_unb, bert_preds)\n","bert_classification = classification_report(y_test_unb, bert_preds.round())\n","bert_confusion = confusion_matrix(y_test_unb, bert_preds.round())\n","\n","print(f'BERT F1: {bert_f1:.4f}')\n","print('AUC_ROC: ' + str(bert_roc_auc))\n","print('Classification Report: ' + bert_classification)\n","summary_path = os.path.join(folder_path, 'classification_report.txt')\n","with open(summary_path, 'w') as f:\n","    f.write(bert_classification)\n","#print('Confusion Matrix: ' + bert_confusion)\n","\n","ax = plt.subplots(figsize=(5, 5))\n","metrics.ConfusionMatrixDisplay.from_predictions(y_test_unb, bert_preds).plot(ax=ax)\n","plt.savefig(os.path.join(folder_path, \"confusionMatrix.png\"))"],"metadata":{"id":"wKfY1omKN_KW"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1YsLMIPFYfhe9hmi1iZa2EvN6x8p0L2FC","timestamp":1697980834513}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}